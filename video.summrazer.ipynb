{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# video.summrazer.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the video from Youtube\n",
    "First of all, we need a way to download the video from youtube. Actually, we don’t need the whole video but only the audio. So we will extract the audio from the video and download only that.\n",
    "\n",
    "The library I used to interoperate with youtube is youtube_dl which you can learn more about on GitHub.\n",
    "\n",
    "So we install the library with pip and download the audio from youtube in the following way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "import youtube_dl\n",
    "\n",
    "\n",
    "ydl_opts = {\n",
    "    'format': 'bestaudio/best',\n",
    "    'postprocessors': [{\n",
    "        'key': 'FFmpegExtractAudio',\n",
    "        'preferredcodec': 'wav',\n",
    "        'preferredquality': '192',\n",
    "    }],\n",
    "    'outtmpl':\".\" + '/video.%(ext)s',\n",
    "}\n",
    "with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
    "    ydl.download(['https://www.youtube.com/watch?v=Irbx9HJtexI'])\n",
    "    \n",
    "absolute_path = \"video.wav\" #file name of your downloaded audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in line 8 we chose to download the audio in wav format, but mp3 or others are also fine if you prefer.\n",
    "In line 15, on the other hand, you must enter the link to the video you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listen to the Audio\n",
    "Did we download the audio correctly? Let’s check by resenting the audio directly from the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from IPython.display import Audio \n",
    "import librosa \n",
    "\n",
    "sampling_rate = 16_000\n",
    "speech, rate = librosa.load(\"video.wav\")\n",
    "\n",
    "Audio(speech,rate=rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Audio to Text\n",
    "The next step is to convert the audio file into text hoping to get a low word error rate. This will be useful since we can then run a summarization NLP algorithm directly on the text.\n",
    "\n",
    "You can read more about the model we will use for text conversion to text here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%capture\n",
    "!pip install transformers\n",
    "from transformers import pipeline\n",
    "\n",
    "model = \"facebook/wav2vec2-large-960h-lv60-self\" #speech to text\n",
    "\n",
    "#speech to text\n",
    "pipe = pipeline(model = model)\n",
    "text = pipe(absolute_path, chunk_length_s=10) \n",
    "\n",
    "#save text\n",
    "text_file = open(\"original_text.txt\", \"w\")\n",
    "n = text_file.write(text[\"text\"])\n",
    "text_file.close()\n",
    "\n",
    "#read article\n",
    "text_article = open(\"original_text.txt\", \"r\").read()\n",
    "print(len(text_article.split()))\n",
    "text_article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Summarization\n",
    "Now what’s left for us to do is to take the text we extracted from the video and summarize it.\n",
    "There are hundreds of summarization models, all you have to do is go to hugging face filter on the summarization button and choose the one that best suits your case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, I will use the google/pegasus-xsum model. You can read the details of this model here (in some future articles I will also go on to explain the theory behind these summarization algorithms).\n",
    "\n",
    "Using these pre-trained models found on HugginFace is really simple, look at I use summarization in a few lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install sentencepiece\n",
    "\n",
    "summarizer = pipeline(\"summarization\", \"google/pegasus-xsum\")\n",
    "tokenizer_kwargs = {'truncation':True,'max_length':512}\n",
    "text_summerization = summarizer(text_article, min_length=30, do_sample=False,**tokenizer_kwargs)\n",
    "\n",
    "print(text_summerization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](image-1.png)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
