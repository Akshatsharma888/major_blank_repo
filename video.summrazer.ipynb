{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# video.summrazer.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the video from Youtube\n",
    "First of all, we need a way to download the video from youtube. Actually, we don’t need the whole video but only the audio. So we will extract the audio from the video and download only that.\n",
    "\n",
    "The library I used to interoperate with youtube is youtube_dl which you can learn more about on GitHub.\n",
    "\n",
    "So we install the library with pip and download the audio from youtube in the following way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in output_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Audio extracted and saved to output_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "# Specify the path to your local video file\n",
    "local_video_path = \"bigo.mp4\"\n",
    "\n",
    "# Load the video clip\n",
    "video_clip = VideoFileClip(local_video_path)\n",
    "\n",
    "# Extract audio from the video clip\n",
    "audio_clip = video_clip.audio\n",
    "\n",
    "# Specify the output audio file name\n",
    "output_audio_path = \"output_audio.wav\"\n",
    "\n",
    "# Write the audio to a WAV file\n",
    "audio_clip.write_audiofile(output_audio_path)\n",
    "\n",
    "# Close the video clip to release resources\n",
    "video_clip.close()\n",
    "\n",
    "print(f\"Audio extracted and saved to {output_audio_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in line 8 we chose to download the audio in wav format, but mp3 or others are also fine if you prefer.\n",
    "In line 15, on the other hand, you must enter the link to the video you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listen to the Audio\n",
    "Did we download the audio correctly? Let’s check by resenting the audio directly from the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pocketsphinx in /usr/local/python/3.10.13/lib/python3.10/site-packages (5.0.3)\n",
      "Requirement already satisfied: sounddevice in /usr/local/python/3.10.13/lib/python3.10/site-packages (from pocketsphinx) (0.4.6)\n",
      "Requirement already satisfied: CFFI>=1.0 in /home/codespace/.local/lib/python3.10/site-packages (from sounddevice->pocketsphinx) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /home/codespace/.local/lib/python3.10/site-packages (from CFFI>=1.0->sounddevice->pocketsphinx) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip install pocketsphinx\n",
    "\n",
    "import speech_recognition as sr\n",
    "\n",
    "# Define the path to your WAV file\n",
    "wav_file = \"output_audio.wav\"\n",
    "\n",
    "# Initialize the recognizer\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Load the audio file\n",
    "with sr.AudioFile(wav_file) as source:\n",
    "    # Listen for the data (load audio to memory)\n",
    "    audio_data = recognizer.record(source)\n",
    "    \n",
    "    # Recognize speech using the Sphinx engine (offline)\n",
    "    try:\n",
    "        text = recognizer.recognize_sphinx(audio_data)\n",
    "        print(\"Extracted text:\", text)\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Sphinx could not understand the audio\")\n",
    "    except sr.RequestError as e:\n",
    "        print(\"Sphinx error; {0}\".format(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Audio to Text\n",
    "The next step is to convert the audio file into text hoping to get a low word error rate. This will be useful since we can then run a summarization NLP algorithm directly on the text.\n",
    "\n",
    "You can read more about the model we will use for text conversion to text here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install transformers\n",
    "from transformers import pipeline\n",
    "\n",
    "model = \"facebook/wav2vec2-large-960h-lv60-self\" #speech to text\n",
    "\n",
    "#speech to text\n",
    "pipe = pipeline(model = model)\n",
    "text = pipe('output_audio.wav', chunk_length_s=10) \n",
    "\n",
    "#save text\n",
    "text_file = open(\"original_text.txt\", \"w\")\n",
    "n = text_file.write(text[\"text\"])\n",
    "text_file.close()\n",
    "\n",
    "#read article\n",
    "text_article = open(\"original_text.txt\", \"r\").read()\n",
    "print(len(text_article.split()))\n",
    "text_article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Summarization\n",
    "Now what’s left for us to do is to take the text we extracted from the video and summarize it.\n",
    "There are hundreds of summarization models, all you have to do is go to hugging face filter on the summarization button and choose the one that best suits your case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, I will use the google/pegasus-xsum model. You can read the details of this model here (in some future articles I will also go on to explain the theory behind these summarization algorithms).\n",
    "\n",
    "Using these pre-trained models found on HugginFace is really simple, look at I use summarization in a few lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /usr/local/python/3.10.13/lib/python3.10/site-packages (0.1.99)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 1.58k/1.58k [00:00<00:00, 7.54MB/s]\n",
      "model.safetensors: 100%|██████████| 1.63G/1.63G [00:11<00:00, 138MB/s] \n",
      "generation_config.json: 100%|██████████| 363/363 [00:00<00:00, 1.92MB/s]\n",
      "vocab.json: 100%|██████████| 899k/899k [00:00<00:00, 1.13MB/s]\n",
      "merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 30.6MB/s]\n",
      "tokenizer.json: 100%|██████████| 1.36M/1.36M [00:00<00:00, 30.2MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': 'The BEGO NOTATION IS USED IN ACADEMICS TO DESCRIBE WRONG TIMES. In the NURSERY PEOPLE TEND TO USE BIGO TO UNDERSTAND DIFFERENT NOTATIONS THAT ARE USED TO MEASURE THE PERFORMANCE OF ALGRIDIM. We will look at real life examples to see how different cars perform in different conditions. We are going to use the MARKER MARKER MOVES TO THE RIGHT IN EACH EACH STEP.'}]\n"
     ]
    }
   ],
   "source": [
    "%pip install sentencepiece\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "# Define the filename here\n",
    "filename = \"original_text.txt\"\n",
    "\n",
    "# Read the text from the file\n",
    "with open(filename, 'r') as file:\n",
    "    text_article = file.read()\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "tokenizer_kwargs = {'truncation':True,'max_length':512}\n",
    "text_summerization = summarizer(text_article, min_length=30, do_sample=False,**tokenizer_kwargs)\n",
    "\n",
    "print(text_summerization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](image-1.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
